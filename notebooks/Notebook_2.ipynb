{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook 2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gagan3012/ML-hackathons/blob/master/notebooks/Notebook_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# GPT-2 Fine-Tuning Tutorial with PyTorch & Huggingface in Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKGBoVwuhM4H"
      },
      "source": [
        "This is a simplified script for fine-tuning GPT2 using Hugging Face's [Transformers library](https://huggingface.co/transformers/) and PyTorch.\n",
        "\n",
        "You should understand the basics of PyTorch and how a training loop works before getting started. [This official PyTorch tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html) serves as an excellent introduction. Familiarity with the workings of GPT2 might be useful but isn't required. The code has been written for clarity and not re-use. I'd advise refactoring it for actual projects. I've liberally taken bits from [Chris McCormick's BERT fine-tuning tutorial](https://mccormickml.com/2019/07/22/BERT-fine-tuning/), [Ian Porter's GPT2 tutorial](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html) and the [Hugging Face Language model fine-tuning script](https://huggingface.co/transformers/v2.0.0/examples.html#language-model-fine-tuning) so full credit to them. Chris' code has pretty much provided the basis for this script - you should definitely check out his [blog](https://mccormickml.com/tutorials/).\n",
        "\n",
        "I should mention what the script doesn't cover:\n",
        "\n",
        "- Using the [Datasets](https://huggingface.co/nlp/) library to load in the dataset and setting up the training workflow, which looks to streamline things rather nicely.\n",
        "- [Accumulated gradients](https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255) - this gives larger effective batch sizes than Colab allows (GPT2 is a large model, and anything more than a batch size of 2 would be enough to get a CUDA out of memory error on Colab).\n",
        "- [Freezing layers](https://github.com/huggingface/transformers/issues/1431). This is the process of only changing the parameters in selected layers, made famous by the [ULMFit](https://arxiv.org/abs/1801.06146) process.\n",
        "- [Using 'past'](https://huggingface.co/transformers/quickstart.html#using-the-past) when generating text. This takes in the previous state when generating successive items of text. I didn't need it.\n",
        "- [Tensor packing](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html). This is a neat way of fitting in as much training data in each batch. \n",
        "- [Hyperparameter search](https://discuss.huggingface.co/t/using-hyperparameter-search-in-trainer/785/10). I settled quickly on values that seemed to produce decent values, without checking if they were optimal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf3Qw77SZGbS"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cedec74-7715-44fb-f26c-5265fa6aef61"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.7.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCCeyhuDHdOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4352d7ad-63db-4891-eb9e-b7f5f5624cc4"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "satxtOn9CzgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29913730-a309-483a-80e5-ac5c166c0c20"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun 21 06:28:30 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    32W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdCML6Parvv"
      },
      "source": [
        "# Create Training Set\n",
        "\n",
        "The data used to finetune the language model is a set of around 1000 DJ biographies, with the aim of generating them in the same general format and style.\n",
        "\n",
        "This data isn't public so if you want to use this script, you'll have to source your own training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya3zsH0r-3JK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "0b6d8cc3-03a0-48b0-aacf-20fd8b9c19ea"
      },
      "source": [
        "# load into a data frame\n",
        "df1 = pd.read_csv('https://raw.githubusercontent.com/adigoryl/Styled-Lyrics-Generator-GPT2/master/datasets/genius_lyrics_v2.csv',header=None)\n",
        "df1.columns = ['type','artist','year','album','track','lyrics']  \n",
        "df = df1.head(1000)\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>artist</th>\n",
              "      <th>year</th>\n",
              "      <th>album</th>\n",
              "      <th>track</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Justin Bieber</td>\n",
              "      <td>2015</td>\n",
              "      <td>Purpose</td>\n",
              "      <td>Love Yourself</td>\n",
              "      <td>For all the times that you rained on my parade...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Justin Bieber</td>\n",
              "      <td>2015</td>\n",
              "      <td>Purpose</td>\n",
              "      <td>Sorry</td>\n",
              "      <td>You gotta go and get angry at all of my honest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Justin Bieber</td>\n",
              "      <td>2012</td>\n",
              "      <td>Believe</td>\n",
              "      <td>As Long As You Love Me</td>\n",
              "      <td>As long as you love me\\nAs long as you love me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Justin Bieber</td>\n",
              "      <td>2015</td>\n",
              "      <td>Purpose</td>\n",
              "      <td>What Do You Mean?</td>\n",
              "      <td>What do you mean? Oh, oh\\nWhen you nod your he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Justin Bieber</td>\n",
              "      <td>2010</td>\n",
              "      <td>My World 2.0</td>\n",
              "      <td>Baby</td>\n",
              "      <td>Oh, woah\\nOh, woah\\nOh, woah\\n\\nYou know you l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>2013</td>\n",
              "      <td>BEYONCÉ</td>\n",
              "      <td>Heaven</td>\n",
              "      <td>I fought for you\\nThe hardest, it made me the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>2016</td>\n",
              "      <td>Lemonade</td>\n",
              "      <td>Daddy Lessons</td>\n",
              "      <td>Yee-haw\\nOoh\\nTexas, Texas (Ooh) Texas\\n\\nCame...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>Countdown</td>\n",
              "      <td>Boy!\\n\\nOh, killing me softly and I'm still fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>2016</td>\n",
              "      <td>Lemonade</td>\n",
              "      <td>Forward</td>\n",
              "      <td>Forward\\nBest foot first just in case\\nWhen we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>2003</td>\n",
              "      <td>Dangerously In Love</td>\n",
              "      <td>Crazy in Love</td>\n",
              "      <td>Yes! So crazy right now!\\nMost incredibly, it'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    type  ...                                             lyrics\n",
              "0    Pop  ...  For all the times that you rained on my parade...\n",
              "1    Pop  ...  You gotta go and get angry at all of my honest...\n",
              "2    Pop  ...  As long as you love me\\nAs long as you love me...\n",
              "3    Pop  ...  What do you mean? Oh, oh\\nWhen you nod your he...\n",
              "4    Pop  ...  Oh, woah\\nOh, woah\\nOh, woah\\n\\nYou know you l...\n",
              "..   ...  ...                                                ...\n",
              "995  Pop  ...  I fought for you\\nThe hardest, it made me the ...\n",
              "996  Pop  ...  Yee-haw\\nOoh\\nTexas, Texas (Ooh) Texas\\n\\nCame...\n",
              "997  Pop  ...  Boy!\\n\\nOh, killing me softly and I'm still fa...\n",
              "998  Pop  ...  Forward\\nBest foot first just in case\\nWhen we...\n",
              "999  Pop  ...  Yes! So crazy right now!\\nMost incredibly, it'...\n",
              "\n",
              "[1000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U3m6wr3Ahzt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ae8433-bb87-45f7-80e8-fcc9025eedb5"
      },
      "source": [
        "df.dropna(inplace=True) #remove NA values\n",
        "bios = df.lyrics.copy() #just use the main bio text in this example\n",
        "bios"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      For all the times that you rained on my parade...\n",
              "1      You gotta go and get angry at all of my honest...\n",
              "2      As long as you love me\\nAs long as you love me...\n",
              "3      What do you mean? Oh, oh\\nWhen you nod your he...\n",
              "4      Oh, woah\\nOh, woah\\nOh, woah\\n\\nYou know you l...\n",
              "                             ...                        \n",
              "995    I fought for you\\nThe hardest, it made me the ...\n",
              "996    Yee-haw\\nOoh\\nTexas, Texas (Ooh) Texas\\n\\nCame...\n",
              "997    Boy!\\n\\nOh, killing me softly and I'm still fa...\n",
              "998    Forward\\nBest foot first just in case\\nWhen we...\n",
              "999    Yes! So crazy right now!\\nMost incredibly, it'...\n",
              "Name: lyrics, Length: 999, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ1oK0kXaV5p"
      },
      "source": [
        "We need to get an idea of how long our training documents are.\n",
        "\n",
        "I'm not going to use the same tokenizer as the GPT2 one, which is a [byte pair encoding tokenizer](https://blog.floydhub.com/tokenization-nlp/). Instead, I'm using a simple one just to get a rough understanding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "f8fc7d8d-95a5-4236-bffd-0f25079e85a2"
      },
      "source": [
        "doc_lengths = []\n",
        "\n",
        "for bio in bios:\n",
        "\n",
        "    # get rough token count distribution\n",
        "    tokens = nltk.word_tokenize(bio)\n",
        "\n",
        "    doc_lengths.append(len(tokens))\n",
        "\n",
        "doc_lengths = np.array(doc_lengths)\n",
        "\n",
        "sns.distplot(doc_lengths)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f25065a7310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6P6bTItJEIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5f8acb-f481-4d19-c6ee-4f969c133c8a"
      },
      "source": [
        "# the max token length   \n",
        "len(doc_lengths[doc_lengths > 768])/len(doc_lengths)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.042042042042042045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63t_69HjlwAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431eda9f-25d9-4625-a02f-af6cd33b5b9e"
      },
      "source": [
        "np.average(doc_lengths)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "424.55055055055055"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuq5bqdr4_a6"
      },
      "source": [
        "Even though these token counts won't match up to the BPE tokenizer's, I'm confident that most bios will be fit under the 768 embedding size limit for the small GPT2 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMml12FJGjPW"
      },
      "source": [
        "# GPT2 Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANJhbBwdxN-b"
      },
      "source": [
        "Although the defaults take care of this,I thought I'd show that you can specify some of the special tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63fa7d0f-2b75-4813-b30f-84df822dbc70"
      },
      "source": [
        "# Load the GPT tokenizer.\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh0XKuDvnryn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65076d6a-a6f1-44f5-decb-f367e00a301c"
      },
      "source": [
        "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|startoftext|> token has the id 50257\n",
            "The end of sequence token <|endoftext|> has the id 50256\n",
            "The padding token <|pad|> has the id 50258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# PyTorch Datasets & Dataloaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lgZoOYkxZfx"
      },
      "source": [
        "GPT2 is a large model. Increasing the batch size above 2 has lead to out of memory problems. This can be mitigated by accumulating the gradients but that is out of scope here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scqrzmqhV__z"
      },
      "source": [
        "batch_size = 2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqGMee7Isfpx"
      },
      "source": [
        "I'm using the standard PyTorch approach of loading data in using a [dataset class](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
        "\n",
        "I'm passing in the tokenizer as an argument but normally I would  instantiate it within the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XJVIetKN-h"
      },
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx] "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Z7aYUgpWrd"
      },
      "source": [
        "To understand how I've used the tokenizer, it's worth reading [the docs](https://huggingface.co/transformers/main_classes/tokenizer.html). I've wrapped each bio in the bos and eos tokens.\n",
        "\n",
        "Every tensor passed to the model should be the same length.\n",
        "\n",
        "If the bio is shorter than 768 tokens, it will be padded to a length of 768 using the padding token. In addition, an attention mask will be returned that needs to be passed to the model to tell it to ignore the padding tokens. \n",
        "\n",
        "If the bio is longer than 768 tokens, it will be truncated without the eos_token. This isn't a problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xza_O1_rD7yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ad4b25-6fdd-42e3-8f1c-7221bf7ad934"
      },
      "source": [
        "dataset = GPT2Dataset(bios, tokenizer, max_length=768)\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  899 training samples\n",
            "  100 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0WeP5PREUuy"
      },
      "source": [
        "# Create the DataLoaders for our training and validation datasets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "# Finetune GPT2 Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "source": [
        "# I'm not really doing anything with the config buheret\n",
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "\n",
        "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBEVY2PYSTXJ"
      },
      "source": [
        "# some parameters I cooked up that work reasonably well\n",
        "\n",
        "epochs = 5\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 100"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCPohrZ-CTWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26924e04-866b-4f10-8485-d40aba6aad61"
      },
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of    450. Loss: 2.029113531112671.   Elapsed: 0:00:58.\n",
            "0:  bipartisan\", where I live, where I\n",
            "\n",
            "And where I'm from, where I'm from, where I'm from\n",
            "And where I'm from\n",
            "\n",
            "Hate on that side\n",
            "And how much I hate you\n",
            "It feels like it always hurts\n",
            "Ooh so good\n",
            "And how much I hate you\n",
            "\n",
            "It feels like it always hurts\n",
            "Ooh so good\n",
            "And how much I hate you\n",
            "It feels like it always hurts\n",
            "Ooh so good\n",
            "And how much I hate you\n",
            "\n",
            "You\n",
            "I hate myself\n",
            "Cause so good\n",
            "Cause so bad\n",
            "\n",
            "And how much I hate you\n",
            "Cause so good\n",
            "\n",
            "Cause so bad\n",
            "Cause so hard\n",
            "I love myself\n",
            "Cause so good\n",
            "Cause so bad\n",
            "Cause so hard\n",
            "I love myself\n",
            "Cause so bad\n",
            "Cause so hard\n",
            "Cause so easy\n",
            "Cause so good\n",
            "Cause so easy\n",
            "\n",
            "Cause so easy\n",
            "Cause so hard\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   200  of    450. Loss: 0.8680258989334106.   Elapsed: 0:01:57.\n",
            "0:  increasing\n",
            "\n",
            "Halo, now\n",
            "(If you want to know what I've been doing to you)\n",
            "\n",
            "Halo-ta-la, now\n",
            "\n",
            "You just had one more chance\n",
            "\n",
            "Halo-ta-la, now (Hey, no)\n",
            "Halo-ta-la, now (Hey, no)\n",
            "\n",
            "Halo-ta-la, now (Hey, no)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   300  of    450. Loss: 1.7209851741790771.   Elapsed: 0:02:55.\n",
            "0: dayAnd a thousand miles of rivers and stars and my own sky…\n",
            "\n",
            "We'll break out of your head and the stars are spinning around us\n",
            "Don't go through my head\"\n",
            "Oh I'll be the one you're always dreaming of\n",
            "To be the one who never goes out, so you can never find a way\n",
            "I'll be the one you always dream of\n",
            "To be the one you always dream of\n",
            "\n",
            "And all you have to do is give up\n",
            "And I'll be the one you always dream of\n",
            "To be the one you always dream of\n",
            "\n",
            "I will be the one you always dream of\n",
            "To be the one you always dream of\n",
            "\n",
            "(Like this post)\n",
            "\n",
            "Do you have one of those, huh\n",
            "Oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh\n",
            "Oh baby, how are\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   400  of    450. Loss: 1.0475828647613525.   Elapsed: 0:03:55.\n",
            "0:  HangI think you need me when you're hurting, just take it away\n",
            "Don't leave me alone\n",
            "Don't give you what you're worth\n",
            "Don't give you what you're worth\n",
            "Don't give you what you're worth\n",
            "Don't give you what you're worth\n",
            "Don't give you what you're worth\n",
            "Don't give you what you're worth\n",
            "Don't give you what you're worth\n",
            "Don't give you what you're worth\n",
            "Don't give you what you're worth\n",
            "Don't give you what you're worth\n",
            "Don't give you what you're worth\n",
            "Don't give you what you're worth\n",
            "\n",
            "Don't give you what you're worth\n",
            "Don't give you what you're worth\n",
            "Don't give you what you're worth\n",
            "\n",
            "  Average training loss: 2.08\n",
            "  Training epoch took: 0:04:25\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.22\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of    450. Loss: 1.4023469686508179.   Elapsed: 0:00:57.\n",
            "0:  foodsI don't know the world\n",
            "A lot of people say that we all\n",
            "Wish we'd never found\n",
            "A way we've found\n",
            "\n",
            "'Cause this is a mess\n",
            "'Cause everybody can forget about you\n",
            "\n",
            "'Cause I know we went crazy\n",
            "We had no choice\n",
            "\n",
            "\"Oh, ooh, you're gone\n",
            "Ah, it's so bittersweet\n",
            "It's so bittersweet\n",
            "It's so bittersweet\n",
            "Oh\n",
            "\"So, uh, now I gotta see\n",
            "\n",
            "And I know that I can't stop\n",
            "\n",
            "\"Oh, ooh, you're gone\n",
            "Ah, it's so bittersweet\n",
            "It's so bittersweet\n",
            "It's so bittersweet\n",
            "It's so bittersweet\n",
            "It's so bittersweet\n",
            "Oh\n",
            "\"Oh, ooh, you're gone\n",
            "Ah, it's so bittersweet\n",
            "It's so bittersweet\n",
            "Oh\n",
            "\n",
            "\"Oh, ooh, you're gone\n",
            "Ah, it's so\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   200  of    450. Loss: 0.9119707345962524.   Elapsed: 0:01:57.\n",
            "0:  trailOh, that one was bad, but that one was alright\n",
            "I should've known better\n",
            "Oh, that one was bad\n",
            "Oh, that one was bad\n",
            "Oh, that one was bad\n",
            "\n",
            "Hey, look at me!\n",
            "I'm the one I've tried to break down\n",
            "You don’t have to worry that I’ll fall\n",
            "Look how hard you pushed me through\n",
            "Don’t have to worry that I’ll break down\n",
            "Don’t have to worry that I’ll break down\n",
            "Ohh, that one was good, but that one was better\n",
            "Ohh, that one was bad, but that one was better\n",
            "Ohh, that one was bad\n",
            "Ohh\n",
            "Ohh\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   300  of    450. Loss: 1.8577890396118164.   Elapsed: 0:02:56.\n",
            "0: intendOh, yeah, yeah\n",
            "Yeah, yeah, yeah\n",
            "\n",
            "Yeah, yeah, yeah, yeah\n",
            "\n",
            "Yeah, yeah, yeah yeah\n",
            "\n",
            "Yeah, yeah, yeah yeah\n",
            "Yeah, yeah, yeah yeah\n",
            "Yeah, yeah, yeah yeah\n",
            "\n",
            "Yes, yeah, yeah, yeah yeah\n",
            "Yeah, yeah, yeah yeah\n",
            "Yeah, yeah, yeah yeah\n",
            "\n",
            "Yeah, yeah, yeah yeah\n",
            "Yeah, yeah, yeah yeah\n",
            "Yeah, yeah, yeah\n",
            "Yep, yeah, yeah yeah\n",
            "Yeah, yeah, yeah yeah\n",
            "Yeah, yeah, yeah yeah\n",
            "Yep, yeah, yeah yeah\n",
            "Yep, yeah, yeah yeah\n",
            "Yeah, yeah, yeah yeah\n",
            "\n",
            "Yes, yeah, yeah, yeah\n",
            "Yeah, yeah, yeah yeah\n",
            "Yeah, yeah, yeah yeah\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   400  of    450. Loss: 1.6972118616104126.   Elapsed: 0:03:55.\n",
            "0:  surroundTired of being down on my knees with nothing to lose\n",
            "When your mind's on me, all that I wanna do is leave\n",
            "It's sad when it's lost, in this moment\n",
            "I love what you do to me, darling\n",
            "I don't know what I could have said, but I'm gonna leave this for a little\n",
            "\n",
            "Oh, and you know I don't really care what you do to me\n",
            "You know I love what you do to me, darling\n",
            "I don't know what I could have said, but I'm gonna leave this for a little\n",
            "\n",
            "Oh, and you know I don't really care what you do to me\n",
            "You know I love what you do to me, darling\n",
            "I don't know what I could have said, but I'm gonna leave this for a little\n",
            "\n",
            "Oh, and you know I don't really care what you do to me\n",
            "You know I love what you do to me, darling\n",
            "I don\n",
            "\n",
            "  Average training loss: 1.22\n",
            "  Training epoch took: 0:04:25\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.20\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of    450. Loss: 1.0745365619659424.   Elapsed: 0:00:58.\n",
            "0:  reflexA moment later a tear stream in through the rain\n",
            "Just as we were leaving\n",
            "We passed it off as nothing and a moment later we were\n",
            "Walking with someone like you\n",
            "Who makes you look down upon the sky and look up into the night?\n",
            "Just as we were leaving\n",
            "We passed it off as nothing and a moment later we were\n",
            "Walking with someone like you\n",
            "Who makes you look down upon the sky and look up into the night?\n",
            "Just as we were leaving\n",
            "\n",
            "There it is... there it is...\n",
            "\n",
            "Oh Lord, there it is...\n",
            "\n",
            "This is my home now, my home\n",
            "I'll never let you in it again\n",
            "There is no one else in this room\n",
            "Where the words are left out\n",
            "'Cause I’ve never been\n",
            "And I’m yours to call\n",
            "\n",
            "I'll never let you in it again\n",
            "There is no one else in this room\n",
            "Where the words are left out\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   200  of    450. Loss: 1.2086268663406372.   Elapsed: 0:01:57.\n",
            "0:  displayI love the way you make me feel\n",
            "I love how you make me feel\n",
            "I love how you make me feel\n",
            "I love how you make me feel\n",
            "\n",
            "I love the way you make me feel\n",
            "I love the way you make me feel\n",
            "\n",
            "I love the way you make me feel\n",
            "I love the way you make me feel\n",
            "\n",
            "I love the way you make me feel\n",
            "I love the way you make me feel\n",
            "\n",
            "I love the way you make me feel\n",
            "I love the way you make me feel\n",
            "I love the way you make me feel\n",
            "\n",
            "I love the way you make me feel\n",
            "\n",
            "I love the way you make me feel\n",
            "I love the way you make me feel\n",
            "\n",
            "I love the way you make me feel\n",
            "I love the way you make me feel\n",
            "\n",
            "I love the way you make me feel\n",
            "I love the way you make me feel\n",
            "I love the way you make me feel\n",
            "I love the way you\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   300  of    450. Loss: 2.3404998779296875.   Elapsed: 0:02:57.\n",
            "0:  pastorWe've been through a lot, yeah\n",
            "I've spent more of my life with you\n",
            "Like the rest of your kind and not afraid to say no to you, yeah\n",
            "You've been my baby, too\n",
            "\n",
            "Don't let you go, I'll take you there\n",
            "I'll take you there too (We'll take you there)\n",
            "I'll take you there too\n",
            "I'll take you there\n",
            "I will take you there\n",
            "\n",
            "No, I won't make you afraid\n",
            "You're a good girl, I'm strong and I can take it, yeah\n",
            "You've been my baby, too\n",
            "\n",
            "Don't let you go, I'll take you there\n",
            "I'll take you there\n",
            "I'll take you there\n",
            "I will take you there\n",
            "I will take you there\n",
            "I will take you there\n",
            "\n",
            "Don't let you go, I'll take you there\n",
            "I'll take you there\n",
            "I'll take you there\n",
            "I will take you there\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   400  of    450. Loss: 1.4127885103225708.   Elapsed: 0:03:56.\n",
            "0:  illicitI like it when they say they want me now\n",
            "But I don't know what to do now\n",
            "So tell me, boy, what you gonna do?\n",
            "I've done too much\n",
            "And you've made too many mistakes\n",
            "And you've been so mean\n",
            "I'm so sorry\n",
            "\n",
            "Oh I got you feeling so different today\n",
            "I'm so sorry\n",
            "I got you feeling so different now\n",
            "I'm so sorry\n",
            "\n",
            "Oh I got you feeling so different today\n",
            "I'm so sorry\n",
            "I got you feeling so different today\n",
            "I'm so sorry\n",
            "\n",
            "I got you feeling so different today\n",
            "I'm so sorry\n",
            "I got you feeling so different today\n",
            "I'm so sorry\n",
            "I got you feeling so different today\n",
            "Oh, it's just a little different today\n",
            "Oh, it's just a little different\n",
            "\n",
            "Hey, I got it now, baby\n",
            "I got it right now\n",
            "\n",
            "I got you feeling so different now\n",
            "I'm so sorry\n",
            "\n",
            "\n",
            "  Average training loss: 1.13\n",
            "  Training epoch took: 0:04:26\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.20\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of    450. Loss: 1.3854124546051025.   Elapsed: 0:00:58.\n",
            "0:  LiberationI said to myself \"Oh, girl, this is stupid, you're so stupid\" (Oh no, no, no) I said I'ma make a toast\n",
            "But I never ever ever said anything, never ever ever said to me\n",
            "You know what I'm thinkin' right now?\n",
            "There ain't no words, no more words\n",
            "But you can say anything you wanna, you know what I mean\n",
            "I swear, it's already been said\n",
            "\n",
            "And I got a dream to make my dreams come true\n",
            "I wanna make my dreams come true\n",
            "I wanna make my dreams come true\n",
            "But girl, you just can't control, so you gotta have some\n",
            "So let's just say that I'll never give up (Let's just say that I'll never give up)\n",
            "\n",
            "So, say that you'll never take my love away\n",
            "\n",
            "And I got a dream to make my dreams come true\n",
            "I wanna make my dreams come true\n",
            "And I\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   200  of    450. Loss: 0.935236394405365.   Elapsed: 0:01:57.\n",
            "0:  NamI'm gonna take it all\n",
            "You're beautiful but I'm flawed\n",
            "I'm gonna pull you out of me\n",
            "I don't want you in my life but I don't want you to be\n",
            "The one thing I love, like you are\n",
            "You're in my life but you're in my world\n",
            "You're never gonna disappear in my world\n",
            "\n",
            "I'm gonna take it all\n",
            "You're beautiful but I'm flawed\n",
            "I'm gonna pull you out of me\n",
            "I don't want you in my life but I don't want you to be\n",
            "The one thing I love, like you are\n",
            "You're in my life but you're in my world\n",
            "You're never gonna disappear in my world\n",
            "\n",
            "I'm gonna take it all\n",
            "You're beautiful but I'm flawed\n",
            "I'm gonna pull you out of me\n",
            "I don't want you in my life but I don't want you to be\n",
            "The one thing I love, like you are\n",
            "You're\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   300  of    450. Loss: 1.1750648021697998.   Elapsed: 0:02:57.\n",
            "0: IONThe world belongs to me\n",
            "\n",
            "I'm a product of my own creation\n",
            "I'm the product of my own design\n",
            "I can make any choice that you want\n",
            "\n",
            "I'm a product of your love\n",
            "I'm the product of your persuasion\n",
            "I can make any choice that you want\n",
            "\n",
            "The way that you smile is a reflection of my true colors\n",
            "A reflection of me\n",
            "You and my world is what makes us free\n",
            "You and your love is the truth that has been shed\n",
            "\n",
            "We are the product of your love\n",
            "We are the product of your freedom\n",
            "We are the products of your love\n",
            "\n",
            "Let me lay down my life\n",
            "Let me show you how\n",
            "\n",
            "All that I do is to live\n",
            "Let me tell you how\n",
            "\n",
            "That's the way that you smile is a reflection of my true colors\n",
            "A reflection of me\n",
            "You and my world is what makes us free\n",
            "You and your love is the truth that has been shed\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   400  of    450. Loss: 1.3809524774551392.   Elapsed: 0:03:56.\n",
            "0:  glimpseIt felt like daylight\n",
            "I walked up to you and took it all in my mind\n",
            "And there was nothing that I could say\n",
            "That it wouldn't sink in, no, you wouldn't leave\n",
            "No, you wouldn't stay\n",
            "No, you wouldn't stay\n",
            "Oh it's no good for you\n",
            "\n",
            "You make me question your intentions\n",
            "And you're the only one I care to call\n",
            "But if you're really that lonely, I bet it's not you\n",
            "You're the only one I care to call\n",
            "But if you're really that lonely, I bet it's not you\n",
            "\n",
            "It's no good for you\n",
            "\n",
            "You make me question your intentions\n",
            "And you're the only one I care to call\n",
            "But if you're really that lonely, I bet it's not you\n",
            "You're the only one I care to call\n",
            "But if you're really that lonely, I bet it's not you\n",
            "\n",
            "It's no good for you\n",
            "\n",
            "I\n",
            "\n",
            "  Average training loss: 1.05\n",
            "  Training epoch took: 0:04:26\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.21\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of    450. Loss: 0.7431923747062683.   Elapsed: 0:00:58.\n",
            "0:  LaureI've been away, and I need you there more\n",
            "You've made my bed aching\n",
            "And you're holding me tight, no, don't let me go, hey\n",
            "\n",
            "You need a little clarity, I'm in too deep\n",
            "You need to know we've got a lot in common\n",
            "So, baby, let's get down from this\n",
            "I'm feeling so obligated\n",
            "\n",
            "I'm so used to this life, feel this touch\n",
            "I don't wanna be here on your worst night\n",
            "\n",
            "I don't need you and I don't need you and I don't need you and I don't need you and I don't need you and I don't need you and I don't need you and I don't need you and I don't need you and I don't need you and I don't need you and I don't need you and I don't need you and I don't need you and I don't need you and I don't need you\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   200  of    450. Loss: 0.8593940734863281.   Elapsed: 0:01:57.\n",
            "0: ismI met you a couple years ago\n",
            "In a café in the middle of town\n",
            "You said you liked being alone\n",
            "But I didn't\n",
            "\n",
            "And yet we made our way on the same old story\n",
            "And we've grown old together\n",
            "I've forgotten our chemistry\n",
            "And even though it's pretty fun we are still friends\n",
            "\n",
            "I'm not the only one in your circle\n",
            "I see things we can't seem to forget\n",
            "And I need you to keep me on the road\n",
            "I'd risk everything to get you close\n",
            "And if you don't want me\n",
            "Just say so\n",
            "It's only right, but you do what you need\n",
            "\n",
            "But there you are, still, still in love\n",
            "Still in love, still in love\n",
            "And there you are, still, still in love\n",
            "\n",
            "And I know that I've been through too much\n",
            "And maybe I'm alone\n",
            "So I hope you and I make this a little more than we've ever been before\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   300  of    450. Loss: 0.8938676714897156.   Elapsed: 0:02:57.\n",
            "0: ounI'm taking too much time\n",
            "I think we don't have the time to waste\n",
            "Maybe it's time I get a little obsessive\n",
            "Maybe it's time I get a little fickle\n",
            "Maybe it's time I let it all get hard on myself\n",
            "Maybe it's time I get a little obsessive\n",
            "Maybe it's time I get a little fickle\n",
            "Maybe it's time I get a little fickle\n",
            "Maybe it's time I get a little fickle\n",
            "Maybe it's time I get a little fickle\n",
            "\n",
            "There’s room and I don’t know where to start\n",
            "I hope your story is one that gets across my heart\n",
            "Cause that’s what makes me who I am\n",
            "\n",
            "Ooh, I can’t wait another minute\n",
            "But at least we could get down to business\n",
            "I guess it’s time we could get a little obsessive\n",
            "Maybe it’s time I get a little fickle\n",
            "Maybe it\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   400  of    450. Loss: 0.8278471231460571.   Elapsed: 0:03:56.\n",
            "0:  electionLamborghinis, Lamborghinis\n",
            "Lamborghinis, Lamborghinis\n",
            "\n",
            "Sessions, sedans, sedans\n",
            "Lamborghinis, Lamborghinis\n",
            "\n",
            "Mulsanne, mulsanne\n",
            "Sessions, sedans, sedans\n",
            "Lamborghinis, Lamborghinis\n",
            "\n",
            "Bikes on the side of the roadway\n",
            "Mulsanne, mulsanne\n",
            "Sessions, sedans, sedans\n",
            "\n",
            "(Catch 'em where you are)\n",
            "Sessions, sedans, sedans\n",
            "\n",
            "Lamborghinis, Lamborghinis\n",
            "Sessions, sedans, sedans\n",
            "\n",
            "Ooh, my, my\n",
            "\n",
            "You know I don’t ever see myself quite the same way\n",
            "\n",
            "Lamborghinis, Lamborghinis\n",
            "\n",
            "And I still love that Bugatti\n",
            "I still love that Bugatti\n",
            "But I still want a Lamborghini\n",
            "I always want a Lamborghini\n",
            "I always\n",
            "\n",
            "  Average training loss: 0.98\n",
            "  Training epoch took: 0:04:26\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 1.23\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:22:56 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "b1c90636-a2ae-4e60-d3f6-ab4a9f7edc8d"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.08</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0:04:25</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.22</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0:04:25</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.13</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0:04:26</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.05</td>\n",
              "      <td>1.21</td>\n",
              "      <td>0:04:26</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.98</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0:04:26</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1               2.08         1.22       0:04:25         0:00:10\n",
              "2               1.22         1.20       0:04:25         0:00:10\n",
              "3               1.13         1.20       0:04:26         0:00:10\n",
              "4               1.05         1.21       0:04:26         0:00:10\n",
              "5               0.98         1.23       0:04:26         0:00:10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "b322a88e-387d-44b3-c97f-348fd4c38468"
      },
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfjYoa6WmkN6"
      },
      "source": [
        "# Display Model Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f13669-b910-44b3-92b1-e7112e25b770"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The GPT-2 model has 148 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "transformer.wte.weight                                  (50259, 768)\n",
            "transformer.wpe.weight                                   (1024, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "transformer.h.0.ln_1.weight                                   (768,)\n",
            "transformer.h.0.ln_1.bias                                     (768,)\n",
            "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
            "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
            "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
            "transformer.h.0.attn.c_proj.bias                              (768,)\n",
            "transformer.h.0.ln_2.weight                                   (768,)\n",
            "transformer.h.0.ln_2.bias                                     (768,)\n",
            "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
            "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
            "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
            "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "transformer.ln_f.weight                                       (768,)\n",
            "transformer.ln_f.bias                                         (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "# Saving & Loading Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dbebed9-2ec2-483c-f3b5-a0d9ee4ae5f4"
      },
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.json',\n",
              " './model_save/merges.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqMzI3VTCZo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529df7d2-e883-4372-b8dd-b49cd6071dc2"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 499792K\n",
            "-rw-r--r-- 1 root root      1K Jun 21 06:52 added_tokens.json\n",
            "-rw-r--r-- 1 root root      1K Jun 21 06:52 config.json\n",
            "-rw-r--r-- 1 root root    446K Jun 21 06:52 merges.txt\n",
            "-rw-r--r-- 1 root root 498448K Jun 21 06:52 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Jun 21 06:52 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Jun 21 06:52 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    878K Jun 21 06:52 vocab.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUFUIQ8Cu8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d59778c-f06e-4106-c84e-6f3c6c324d19"
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 487M Jun 21 06:52 ./model_save/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLf6rbRglYhQ"
      },
      "source": [
        "# Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4XhewaV93-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de501224-bd24-44e6-87fc-09094e466788"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|>\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 300,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[50257]], device='cuda:0')\n",
            "0: The night's the last of me, it was a life changing night\n",
            "I woke up to the taste of her perfume in my face\n",
            "I spent my last breath taking deep breath\n",
            "She was the one to call, 'cause her name on the credits\n",
            "She gave me back a world I wouldn't change\n",
            "Even her friends were saying the least\n",
            "How we used to laugh when I'm in the clouds\n",
            "\n",
            "She wasn't my baby, not ever\n",
            "Even when she was my lover\n",
            "She was the only thing I wanted\n",
            "I'd stand by her side\n",
            "In the rain, the stars came alive\n",
            "In the waves and the silence\n",
            "It was the summer air\n",
            "It was the night that I was dreaming about\n",
            "\n",
            "Her body language's whisper\n",
            "Shakin', whisper, whisper\n",
            "She said, \"Never, never, never\n",
            "Even when we're together\n",
            "Never, never\n",
            "\"Oh,\" the night turned into a day\n",
            "And the nights turned into days\n",
            "\n",
            "It was the summer air\n",
            "It was the night that I was dreaming about\n",
            "(It was the summer air)\n",
            "It was the night that I was dreaming about\n",
            "\n",
            "She wasn't my baby, not ever\n",
            "Even when she was my lover\n",
            "She was the only thing I wanted\n",
            "I'd stand by her side\n",
            "In the rain, the stars came alive\n",
            "In the waves and the silence\n",
            "It was the summer air\n",
            "It was the night that I was dreaming about\n",
            "\n",
            "It\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}